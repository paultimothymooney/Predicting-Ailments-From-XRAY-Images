{"nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "bbb7a259-8780-4135-9b4a-1af6e69bf323", "_uuid": "d189340a841fb5fa3f5e469e41e883daa27dfa42"}, "source": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "273657be-cc72-41e9-bdc1-0924e660d68f", "_uuid": "e6973045586ce95d5a86988c044e545135302e73"}, "source": ["**Predicting Pathologies In X-Ray Images** --work in progress--\n", "\n", "The NIH Clinical Center recently released over 100,000 anonymized chest x-ray images and their corresponding data to the scientific community. The release will allow researchers across the country and around the world to freely access the datasets and increase their ability to teach computers how to detect and diagnose disease. Ultimately, this artificial intelligence mechanism can lead to clinicians making better diagnostic decisions for patients.\n", "\n", "https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n", "\n", "http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ddf15bb7-b9e1-4063-88d0-4bae818cf6e9", "_uuid": "108abe5e061c38256c0b3dba2616bba3308eb8b3"}, "source": ["This script is Part 2 of https://www.kaggle.com/paultimothymooney/predict-pathology-full-x-ray-part-1.\n", "* This script is Part 2 of https://www.kaggle.com/paultimothymooney/predict-pathology-full-x-ray-part-1 which gives as an output NPZ versions of X_train, Y_train, X_test, and Y_Test.  \n", "* The NPZ files from the X-Ray Part 1 Notebook are too big to be opened within a Kaggle Kernel, unfortunately, so I had to use a different method for Part 2.\n", "* H5 files are much better for storing very large arrays and Kaggle User Kevin Mader built a great script that loads the images as H5 files instead of NPZ files.  As such, I elected to use his script as an input instead of mine.  https://www.kaggle.com/kmader/create-a-mini-xray-dataset-equalized.\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "564eae7f-c5e0-492a-a76d-aa2182b343c9", "_uuid": "0b618032d6f7ef9669135440d927a147d0d4e5f5"}, "source": ["*Step 1: Import Libraries*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "f37f94fe-9c6b-461f-909e-b730cc8194cf", "_uuid": "1550fe974cc89ea97d0631bd90547378597b560b", "_kg_hide-input": true}, "source": ["import pandas as pd\n", "import numpy as np\n", "import os\n", "import itertools\n", "from glob import glob\n", "import random\n", "import matplotlib.pylab as plt\n", "import cv2\n", "import sklearn\n", "from sklearn import model_selection\n", "from sklearn.model_selection import train_test_split, learning_curve\n", "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n", "import keras\n", "from keras.models import Sequential, model_from_json\n", "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n", "from keras import callbacks\n", "from keras.utils.vis_utils import plot_model\n", "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n", "from keras.utils.io_utils import HDF5Matrix\n", "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras import backend as K\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.utils import class_weight\n", "from keras.applications.mobilenet import MobileNet\n", "from keras.callbacks import Callback,ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n", "import h5py\n", "%matplotlib inline"], "execution_count": 1}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a8377e11-3a1b-4a5f-a4b0-34971045c36c", "_uuid": "0b7f3d15ddc6cde855bb0fa15dc2aafa97413fcd"}, "source": ["*Step 2: Load Data*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "592e860f-3900-483e-a0e8-88b062acc77f", "_uuid": "08f4576344a703a24b206c1acdabca90ebf2cd10"}, "source": ["disease_vec_labels = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis',\n", " 'Hernia','Infiltration','Mass','Nodule','Pleural_Thickening','Pneumonia','Pneumothorax']\n", "dict_characters = {0:'Atelectasis',1:'Cardiomegaly',2:'Consolidation',3:'Edema',4:'Effusion',5:'Emphysema',6:'Fibrosis',\n", " 7:'Hernia',8:'Infiltration',9:'Mass',10:'Nodule',11:'Pleural_Thickening',12:'Pneumonia',13:'Pneumothorax'}\n", "h5_path = '../input/create-a-mini-xray-dataset-equalized/chest_xray.h5'\n", "disease_vec_labels = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis',\n", " 'Hernia','Infiltration','Mass','Nodule','Pleural_Thickening','Pneumonia','Pneumothorax']\n", "disease_vec = []\n", "with h5py.File(h5_path, 'r') as h5_data:\n", "    all_fields = list(h5_data.keys())\n", "    for c_key in all_fields:\n", "        print(c_key, h5_data[c_key].shape, h5_data[c_key].dtype)\n", "    for c_key in disease_vec_labels:\n", "        disease_vec += [h5_data[c_key][:]]\n", "disease_vec = np.stack(disease_vec,1)\n", "print('Disease Vec:', disease_vec.shape)"], "execution_count": 2}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "8c015e98-7f8a-49c3-8565-af29fb3ae8dd", "_uuid": "b5e38a9380a5f8b8d01e415414fb9321364f3d51"}, "source": ["img_ds = HDF5Matrix(h5_path, 'images')\n", "split_idx = img_ds.shape[0]//2\n", "train_ds = HDF5Matrix(h5_path, 'images', end = split_idx)\n", "test_ds = HDF5Matrix(h5_path, 'images', start = split_idx)\n", "train_dvec = disease_vec[0:split_idx]\n", "test_dvec = disease_vec[split_idx:]\n", "print('Train Shape', train_ds.shape, 'test shape', test_ds.shape)\n", "\n", "X = img_ds\n", "y = disease_vec\n", "X = np.asarray(X)\n", "y = np.asarray(y)\n", "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n", "# Reduce Sample Size for DeBugging\n", "X_train = X_train[0:500000] \n", "Y_train = Y_train[0:500000]\n", "X_test = X_test[0:200000] \n", "Y_test = Y_test[0:200000]\n", "\n", "print(\"X_train\",X_train.shape)\n", "print(\"Y_train\",Y_train.shape)\n", "print(\"X_test\",X_test.shape)\n", "print(\"Y_test\",Y_test.shape)"], "execution_count": 3}, {"cell_type": "markdown", "metadata": {"_cell_guid": "92cb4d2d-31e9-4a92-a961-a77c6586ca89", "_uuid": "03125fec0b38028a6ffe55cc0ce3e2ef2d89afe7"}, "source": ["*Step 3: Define Helper Functions*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "9ba4ee7f-4748-4889-aabe-992e6bdb2af7", "_uuid": "3d69da8afdc2d338c7a0f5aeb8f44ee32e9ab7bf", "collapsed": true}, "source": ["class MetricsCheckpoint(Callback):\n", "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n", "    def __init__(self, savepath):\n", "        super(MetricsCheckpoint, self).__init__()\n", "        self.savepath = savepath\n", "        self.history = {}\n", "    def on_epoch_end(self, epoch, logs=None):\n", "        for k, v in logs.items():\n", "            self.history.setdefault(k, []).append(v)\n", "        np.save(self.savepath, self.history)\n", "\n", "def plotKerasLearningCurve():\n", "    plt.figure(figsize=(10,5))\n", "    metrics = np.load('logs.npy')[()]\n", "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n", "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n", "        l = np.array(metrics[k])\n", "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n", "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n", "        y = l[x]\n", "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n", "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n", "    plt.legend(loc=4)\n", "    plt.axis([0, None, None, None]);\n", "    plt.grid()\n", "    plt.xlabel('Number of epochs')\n", "\n", "def plot_learning_curve(history):\n", "    plt.figure(figsize=(8,8))\n", "    plt.subplot(1,2,1)\n", "    plt.plot(history.history['acc'])\n", "    plt.plot(history.history['val_acc'])\n", "    plt.title('model accuracy')\n", "    plt.ylabel('accuracy')\n", "    plt.xlabel('epoch')\n", "    plt.legend(['train', 'test'], loc='upper left')\n", "    plt.savefig('./accuracy_curve.png')\n", "    #plt.clf()\n", "    # summarize history for loss\n", "    plt.subplot(1,2,2)\n", "    plt.plot(history.history['loss'])\n", "    plt.plot(history.history['val_loss'])\n", "    plt.title('model loss')\n", "    plt.ylabel('loss')\n", "    plt.xlabel('epoch')\n", "    plt.legend(['train', 'test'], loc='upper left')\n", "    plt.savefig('./loss_curve.png')\n", "\n", "def plot_confusion_matrix(cm, classes,\n", "                          normalize=False,\n", "                          title='Confusion matrix',\n", "                          cmap=plt.cm.Blues):\n", "    \"\"\"\n", "    This function prints and plots the confusion matrix.\n", "    Normalization can be applied by setting `normalize=True`.\n", "    \"\"\"\n", "    plt.figure(figsize = (5,5))\n", "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n", "    plt.title(title)\n", "    plt.colorbar()\n", "    tick_marks = np.arange(len(classes))\n", "    plt.xticks(tick_marks, classes, rotation=90)\n", "    plt.yticks(tick_marks, classes)\n", "    if normalize:\n", "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n", "\n", "    thresh = cm.max() / 2.\n", "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n", "        plt.text(j, i, cm[i, j],\n", "                 horizontalalignment=\"center\",\n", "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n", "    plt.tight_layout()\n", "    plt.ylabel('True label')\n", "    plt.xlabel('Predicted label')\n"], "execution_count": 4}, {"cell_type": "markdown", "metadata": {"_cell_guid": "097639d9-3c33-46c9-9445-04244cdde9d1", "_uuid": "68e020bca51f005ca79678411cd76f7c4c570677"}, "source": ["*Step 4: Evaluate Convolutional Network*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "cd14d49d-c860-478c-bcfa-5e17f24f380f", "_uuid": "afbf5e77a674fb688c4ee61ce0779dd6980d044c"}, "source": ["def runCNNconfusion(a,b,c,d):\n", "    # Set the CNN model \n", "    # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n", "    batch_size = 128\n", "    num_classes = 14\n", "    epochs = 4 \n", "        # input image dimensions\n", "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n", "    input_shape = (img_rows, img_cols, 1)\n", "    model = Sequential()\n", "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n", "                     activation ='relu', input_shape = input_shape))\n", "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n", "                     activation ='relu'))\n", "    model.add(MaxPool2D(pool_size=(2,2)))\n", "    model.add(BatchNormalization())\n", "    model.add(Dropout(0.25))\n", "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n", "                     activation ='relu'))\n", "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n", "                     activation ='relu'))\n", "    model.add(MaxPool2D(pool_size=(2,2)))\n", "    model.add(BatchNormalization())\n", "    model.add(Dropout(0.25))\n", "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n", "                     activation ='relu'))\n", "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n", "                     activation ='relu'))\n", "    model.add(MaxPool2D(pool_size=(2,2)))\n", "    model.add(BatchNormalization())\n", "    model.add(Dropout(0.25))\n", "    model.add(Flatten())\n", "    #model.add(Dense(1024, activation = \"relu\"))\n", "    #model.add(Dropout(0.5))\n", "    model.add(Dense(512, activation = \"relu\"))\n", "    model.add(Dropout(0.5))\n", "    model.add(Dense(num_classes, activation = \"softmax\"))\n", "    # Define the optimizer\n", "    optimizer = RMSprop(lr=0.001, decay=1e-6)\n", "    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n", "    datagen = ImageDataGenerator(\n", "        featurewise_center=False,  # set input mean to 0 over the dataset\n", "        samplewise_center=False,  # set each sample mean to 0\n", "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n", "        samplewise_std_normalization=False,  # divide each input by its std\n", "        zca_whitening=False,  # apply ZCA whitening\n", "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n", "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n", "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n", "#         horizontal_flip=True,  # randomly flip images\n", "        vertical_flip=False)  # randomly flip images\n", "    datagen.fit(a)\n", "    history = model.fit_generator(datagen.flow(a,b, batch_size=32),\n", "                        steps_per_epoch=len(a) / 32, epochs=epochs,  validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n", "    # , class_weight = class_weight\n", "    score = model.evaluate(c,d, verbose=0) \n", "    print('\\nKeras CNN - accuracy:', score[1],'\\n')\n", "    plot_learning_curve(history)\n", "    plt.show()\n", "    plotKerasLearningCurve()\n", "    plt.show()\n", "    Y_pred = model.predict(c)\n", "    #print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(Y_pred, axis=1), target_names=list(dict_characters.values())), sep='')    \n", "    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n", "    Y_true = np.argmax(d,axis = 1) \n", "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n", "    plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n", "    plt.show()\n", "runCNNconfusion(X_train, Y_train, X_test, Y_test)"], "execution_count": 5}, {"cell_type": "markdown", "metadata": {"_cell_guid": "6b9143f2-2cb9-4ce5-ad75-3574a34a35f9", "_uuid": "6f65311c9640cc33368ffc568972dba4ec913ea6"}, "source": ["This model is unsatisfactory due to low accuracy and high bias.  Perhaps the accuracy would increase if we increased the number of epochs and the training time, but then we would surpass the limits of the Kaggle Kernel.  I will use a transfer learning approach instead to save time."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "925da79f-e157-4f80-8f8f-e839f68b8238", "_uuid": "bb6786a88f27d38b0ac02733df53f8308d13819d"}, "source": ["*Step 5: Evaluate Transfer Learning Approach*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "892a2283-382b-40de-9db0-57b649ab7ec9", "_uuid": "e49aa239a1a24a28b11255d613c90f1eee619c68"}, "source": ["def MOBILENET(a,b,c,d):\n", "    raw_model = MobileNet(input_shape=(None, None, 1), include_top = False, weights = None)\n", "    full_model = Sequential()\n", "    full_model.add(AveragePooling2D((2,2), input_shape = img_ds.shape[1:]))\n", "    full_model.add(BatchNormalization())\n", "    full_model.add(raw_model)\n", "    full_model.add(Flatten())\n", "    full_model.add(Dropout(0.5))\n", "    full_model.add(Dense(64))\n", "    full_model.add(Dense(disease_vec.shape[1], activation = 'sigmoid'))\n", "    full_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n", "    full_model.summary()\n", "    file_path=\"weights.best.hdf5\"\n", "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n", "    early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=3)\n", "    callbacks_list = [checkpoint, early, MetricsCheckpoint('logs')] #early\n", "    history = full_model.fit(X_train, Y_train, \n", "                   validation_data = (X_test, Y_test),\n", "                   epochs=10, \n", "                   verbose = True,\n", "                  shuffle = 'batch',\n", "                  callbacks = callbacks_list)\n", "    plot_learning_curve(history)\n", "    plt.show()\n", "    plotKerasLearningCurve()\n", "    plt.show()\n", "    model = full_model\n", "    score = model.evaluate(X_test, Y_test, verbose=0)\n", "    print('\\nMobileNet - accuracy:', score[1],'\\n')\n", "    y_pred = model.predict(X_test)\n", "    map_characters = dict_characters\n", "    Y_pred_classes = np.argmax(y_pred,axis=1) \n", "    Y_true = np.argmax(Y_test,axis=1)\n", "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n", "    plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n", "    plt.show()\n", "MOBILENET(X_train, Y_train, X_test, Y_test)"], "execution_count": 6}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ef08f075-3a87-4be0-b027-b5c18ad4980f", "_uuid": "8cdfe0f6fa85c2578d9bef21e6b301ce855f6d5a"}, "source": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "6bf1e200-6aae-4b64-b924-bc4f4e03d751", "_uuid": "12519af48d96a56d2cf5c92f0dc451c79b089754"}, "source": ["Despite having 87% accuracy, it looks like our MobileNet model is still too biased to be reliable.  The bias appears to be in favor of the Infiltration, Effusion, and Atelectasis classes and against every other class.  I will troubleshoot this another day."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e5f2dd23-b5eb-44c2-a8b5-2226544db92e", "_uuid": "db68796442426c50b5cc07675aa9fcc8f3bebdd3"}, "source": ["This script is Part 2 of https://www.kaggle.com/paultimothymooney/predict-pathology-full-x-ray-part-1."]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5ce4db04-b432-4cce-981d-9a2c7cd1f5da", "_uuid": "2288b8b7c237f46fcac314103a2860898041a134", "collapsed": true}, "source": [], "execution_count": null}], "metadata": {"language_info": {"name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1}